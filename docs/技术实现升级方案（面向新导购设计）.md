# 技术实现升级方案（面向新导购设计）

## 1. 文档目标

本文基于当前仓库实现（LangGraph 双角色智能体 + 工具调用 + Streamlit）提出一套可渐进落地的升级方案，以满足你提出的“导购智能体 2.0”设计：

- 引入 **Orchestrator（动态编排层）**；
- 引入 **商品理解 / 用户理解** 两大能力模块；
- 形成“欢迎语 → 编排计划 → 技能执行 → 导购回复”的稳定流程；
- 提供可观测日志、评估框架与启动脚本规范。

---

## 2. 当前项目能力与差距

## 2.1 当前已具备

1. 对话编排框架：LangGraph 节点化流程（sales / support / tool / human approval）。
2. 工具机制：已有结构化搜索、向量搜索、购物车、升级路由等。
3. 前端：Streamlit 基础会话界面，支持审批中断与恢复。
4. 测试：已有单元测试骨架（graph/tool/assistant）。

## 2.2 与新需求的核心差距

1. **无显式 Orchestrator**：当前是“助手直接决定工具调用”，缺少“先输出计划对象”的强制阶段。
2. **用户理解模块缺失**：没有长期画像与行为摘要聚合协议。
3. **商品理解模块未产品化**：虽然你已有离线分析输出（`products_analyzed.csv`），但缺少“分维度归一化/映射/概览接口”。
4. **日志体系不足**：缺少按模块前缀、可追踪 LLM I/O 的结构化日志。
5. **评估体系不足**：缺少 LLM-as-judge 的质量评估脚本与基准集。
6. **脚本与目录规范缺失**：尚未形成你要求的启动脚本和模块目录。

---

## 3. 升级后的目标架构

建议采用“3 核心模块 + 1 编排层 + 2 基础设施层”：

1. `assistant/`：导购回复生成（面向用户）
2. `product_understanding/`：离线汇总 + 在线分布查询 + 搜索技能
3. `user_understanding/`：用户画像汇总与更新（前端 mock 触发）
4. `orchestrator/`：先规划后执行的计划层
5. `logging/`：结构化日志与 trace_id
6. `evaluation/`：自动评测（含 LLM Judge）

推荐目录（在当前项目内逐步演进）：

```text
assistant/
  prompts/
  service.py
  schemas.py

product_understanding/
  process_products.py                # 已有
  output_logs/products_analyzed.csv  # 已有
  service.py                         # 新增：分布查询、概览、欢迎语
  schemas.py

user_understanding/
  service.py                         # 新增：画像生成、更新、个性化欢迎语
  schemas.py

orchestrator/
  planner.py                         # 新增：plan_skills / 思考块
  schemas.py

data/
  profiles/
  product_summaries/

Logs/
  assistant_*.log
  product_*.log
  user_*.log
  orchestrator_*.log

evaluation/
  datasets/
  run_eval.py
  llm_judge.py

scripts/
  setup_conda_env.sh
  start_product_module.sh
  start_user_module.sh
  start_agent_module.sh
  start_web.sh
```

---

## 4. 关键流程重构（强制“思考阶段”）

## 4.1 统一调用链

每轮用户输入后，执行以下固定链路：

1. **读取上下文**：
   - 用户画像 markdown（长期）
   - 最近对话摘要（短期）
   - 店铺内容分布简介
   - 当前地域/季节/天气（可选）
2. **Orchestrator 产出计划对象**（JSON）
3. **按计划执行技能**（product/user/web/compare/style 等）
4. **将技能结果注入 Assistant 上下文**
5. **Assistant 生成面向用户回复**（补信息 + 推荐 + 轻引导）
6. **写日志与评估样本**（异步）

## 4.2 Planner 输出协议（建议最终采用 Function Calling）

字段建议：

- `stage`: `early|clarify|converge`
- `intent`: 分类/场景/风格/效果/预算/尺码/季节/约束
- `gap_assessment`: 缺口槽位与重要性
- `tool_plan[]`: tool、priority、must、reason、args
- `questions_to_ask[]`: 面向用户立场的问题（最多 2 个）
- `response_strategy`: 先推荐后提问等策略
- `confidence`: 0~1

落地原则：

1. Planner 只产出计划，不直接面向用户。
2. Assistant 不再自行随意调用工具，只消费执行后的结构化结果。
3. 若计划 JSON 解析失败，走安全降级：
   - `pure_clarify` + 最小工具集合（`product_distribution`）

---

## 5. 商品理解模块（product_understanding）落地方式

## 5.1 输入

直接使用你已产出的：

- `./product_understanding/output_logs/products_analyzed.csv`

核心字段：

- `category_path`（按 `>` 分层）
- `tags`（逗号分割）
- `target_audience`
- `usage_scene`
- `season`
- `key_attributes/material/features/selling_points`

## 5.2 离线新增任务

1. **Top50 词频统计**（各维度）
2. **归一化体系构建**（LLM + 人审）
3. **映射关系输出**（原始词 -> 归一化词）
4. **每个归一化项生成商品概览 + 示例商品**
5. **生成店铺内容分布简介**
6. **生成 10 条店铺欢迎语**

## 5.3 在线技能接口（建议）

1. `product_distribution(dim, key, tenant_id)`
   - 输出：该维度 key 的商品数、占比、示例商品 markdown
2. `product_search_fuzzy(intent_slots)`
   - 输出：候选 key、方向性推荐、示例商品
3. `product_search_exact(query)`
   - 输出：搜索结果 topN + 标准化字段
4. `result_summarize(user_goal, items)`
   - 输出：满足度判断、改进 query、精选 ID、摘要

## 5.4 与“搜索 API 对接指南”衔接

- 封装 `search_client.py`：
  - 请求重试、超时、熔断
  - 统一返回 schema（避免 Assistant 关心接口细节）
- 将 top30 标题交给 LLM 做“满足度 + 改写 query + 精选”后处理。

---

## 6. 用户理解模块（user_understanding）落地方式

## 6.1 输入（前端 mock）

按你的要求，初期不做真实埋点系统，前端维护：

- 点击、加购、购买（最近 20）
- 搜索记录（最近 40）
- AI 导购压缩对话（最近 40）

## 6.2 输出

1. 用户画像 markdown：
   - 稳定偏好
   - 使用场景偏好
   - 明确约束
   - 行为证据摘要
2. 更新元信息：
   - 更新时间
   - 触发事件类型（对话/进入/站内事件）
3. 个性化欢迎语
4. 离线推荐 list（商品 ID 列表 + 推荐话术）

## 6.3 更新策略

1. **手动触发优先**：前端按钮“更新画像”。
2. **对话结束后触发（后续）**：可异步调用 `memory_update`。
3. **冲突处理**：新证据覆盖旧弱证据，保留来源链路。

## 6.4 画像与当前意图解耦

在 Prompt 注入时明确：

- 画像是背景信息，不应覆盖用户当前明确需求。
- 当“当前输入”与“画像偏好”冲突时，以当前输入优先。

---

## 7. Assistant 模块升级策略

## 7.1 角色职责收敛

Assistant 仅负责：

1. 解释技能结果
2. 组织推荐理由
3. 提出 1~2 个贴心问题
4. 维持语气一致（善解人意/贴心/专业/聪明）

## 7.2 输出风格模板（建议）

每轮尽量遵循：

1. 先肯定与理解用户目标
2. 给 2~3 条可执行建议/推荐方向
3. 补 1~2 个用户立场问题（感受/场景/风格/预算/雷区）

避免“参数盘问式”提问。

---

## 8. Web Search 技能触发策略（Tavily）

## 8.1 触发白名单

仅在以下场景触发 `web_search_trend`：

1. 时效趋势（当季流行、热点风格）
2. 新术语解释（用户不知道商品名）
3. 需要外部知识做穿搭文化补充

## 8.2 非触发场景

- 站内商品信息已足够
- 仅需常规推荐
- 用户已经给出明确商品目标

## 8.3 输出注入方式

Web 结果只注入“摘要结论 + 可信来源列表（title/url）”；避免把冗长网页文本直接灌入最终回复。

---

## 9. 日志与可观测性

## 9.1 日志文件前缀规范

- `Logs/orchestrator_YYYYMMDD.log`
- `Logs/assistant_YYYYMMDD.log`
- `Logs/product_YYYYMMDD.log`
- `Logs/user_YYYYMMDD.log`
- `Logs/eval_YYYYMMDD.log`

## 9.2 每条日志最小字段

- `trace_id`
- `session_id`
- `module`
- `event`
- `input_payload`
- `output_payload`
- `latency_ms`
- `model_name`
- `token_usage`
- `status`

重点：记录 LLM 输入输出时，需脱敏（例如 hash user_id，隐藏手机号/邮箱）。

---

## 10. 评估体系（TDD + LLM 输出不确定性）

## 10.1 评估维度

1. 意图识别完整度（槽位覆盖）
2. 提问质量（是否用户立场、是否超过 2 问）
3. 推荐相关性（商品与目标匹配）
4. 策略合理性（缺口大先问，缺口小先推）
5. 安全与合规（不编造、不越权承诺）

## 10.2 评估流程

1. 构造评测集（真实/合成对话）
2. 运行 Orchestrator + Skills + Assistant
3. 用 LLM Judge + 规则打分
4. 输出维度分、失败样本与改进建议

## 10.3 最小可行评测脚本

- `evaluation/run_eval.py`
- `evaluation/llm_judge.py`
- `evaluation/datasets/*.jsonl`

---

## 11. 分阶段实施计划

## Phase 1（1~2 周）

- 补齐模块目录与接口 schema
- 实现 Orchestrator JSON 输出 + 执行器
- 接入 `products_analyzed.csv` 的分布查询
- 前端增加“用户画像 mock 配置 + 更新画像”

## Phase 2（2~3 周）

- 接入搜索 API + `result_summarize`
- 接入 Tavily web search（严格触发）
- 完成日志与 trace 体系
- 上线评测脚本

## Phase 3（2 周）

- 个性化欢迎语与离线推荐 list
- 对话摘要压缩（超过 10 轮自动压缩）
- 策略 A/B（recommend-first vs ask-first）

---

## 12. 风险与规避

1. **Planner 过度复杂**：先固定 JSON schema，新增字段要版本化。
2. **LLM 非确定性**：必须增加规则校验层 + 回退策略。
3. **上下文膨胀**：采用“结构化摘要 + topK 证据”注入，限制 token。
4. **工具级联超时**：设置超时预算与 early return。
5. **前端可解释性不足**：左栏展示“计划对象 + 工具结果 + 最终回复”。

---

## 13. 与当前代码的最小融合路径

在不推翻现有 `src/graph.py` 的前提下，可先新增两个节点：

1. `orchestrator_planner`
2. `execute_skill_plan`

然后将原 `sales_rep -> sales_tools` 的流程改为：

`user_input -> orchestrator_planner -> execute_skill_plan -> sales_rep_response`

这样可以平滑升级，避免一次性重写。

